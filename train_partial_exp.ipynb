{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mROBOMIMIC WARNING(\n",
      "    No private macro file found!\n",
      "    It is recommended to use a private macro file\n",
      "    To setup, run: python /home/ns1254/miniconda3/envs/equidiff/lib/python3.9/site-packages/robomimic/scripts/setup_macros.py\n",
      ")\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/ns1254/miniconda3/envs/equidiff/lib/python3.9/site-packages/robosuite/scripts/setup_macros.py (macros.py:55)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Warning: make sure gym is installed if you want to use the GymWrapper.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# use line-buffering for both stdout and stderr\n",
    "# sys.stdout = open(sys.stdout.fileno(), mode='w', buffering=1)\n",
    "# sys.stderr = open(sys.stderr.fileno(), mode='w', buffering=1)\n",
    "\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import pathlib\n",
    "from equi_diffpo.workspace.base_workspace import BaseWorkspace\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    " \n",
    " \n",
    "import os\n",
    "import hydra\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "import pathlib\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import random\n",
    "import wandb\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import shutil\n",
    "from equi_diffpo.workspace.base_workspace import BaseWorkspace\n",
    "from equi_diffpo.policy.diffusion_unet_hybrid_image_policy import DiffusionUnetHybridImagePolicy\n",
    "from equi_diffpo.dataset.base_dataset import BaseImageDataset\n",
    "from equi_diffpo.env_runner.base_image_runner import BaseImageRunner\n",
    "from equi_diffpo.common.checkpoint_util import TopKCheckpointManager\n",
    "from equi_diffpo.common.json_logger import JsonLogger\n",
    "from equi_diffpo.common.pytorch_util import dict_apply, optimizer_to\n",
    "from equi_diffpo.model.diffusion.ema_model import EMAModel\n",
    "from equi_diffpo.model.common.lr_scheduler import get_scheduler\n",
    "\n",
    "from equi_diffpo.dataset.robomimic_replay_image_dataset import RobomimicReplayImageDataset \n",
    "from equi_diffpo.env_runner.robomimic_image_runner import RobomimicImageRunner\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, Sampler \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025_01_07_01_43'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = f\"{datetime.now():%Y_%m_%d_%H_%M}\"\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = {\n",
    "    'stack_d1': 400,\n",
    "    'stack_three_d1': 400,\n",
    "    'square_d2': 1200,\n",
    "    'threading_d2': 400,\n",
    "    'coffee_d2': 1200,\n",
    "    'three_piece_assembly_d2': 500,\n",
    "    'hammer_cleanup_d1': 500,\n",
    "    'mug_cleanup_d1': 1200,\n",
    "    'kitchen_d1': 800,\n",
    "    'nut_assembly_d0': 500,\n",
    "    'pick_place_d0': 1000,\n",
    "    'coffee_preparation_d1': 800,\n",
    "    'tool_hang': 700,\n",
    "    'can': 400,\n",
    "    'lift': 400,\n",
    "    'square': 400,\n",
    "}\n",
    "\n",
    "def get_ws_x_center(task_name):\n",
    "    if task_name.startswith('kitchen_') or task_name.startswith('hammer_cleanup_'):\n",
    "        return -0.2\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "def get_ws_y_center(task_name):\n",
    "    return 0.\n",
    "\n",
    "OmegaConf.register_new_resolver(\"get_max_steps\", lambda x: max_steps[x], replace=True)\n",
    "OmegaConf.register_new_resolver(\"get_ws_x_center\", get_ws_x_center, replace=True)\n",
    "OmegaConf.register_new_resolver(\"get_ws_y_center\", get_ws_y_center, replace=True)\n",
    "\n",
    "# allows arbitrary python code execution in configs using the ${eval:''} resolver\n",
    "OmegaConf.register_new_resolver(\"eval\", eval, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python train.py --config-name=train_diffusion_unet task_name=square_d2 \n",
    "#            n_demo=100 dataset_path=/home/ns1254/dataset_mimicgen/square134_2_0ind_abs.hdf5 \n",
    "#            dataset_filter_key=\"g40b30\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segs_todo: remove\n",
      "dataset_path: /home/ns1254/dataset_mimicgen/square134_2_0ind_abs.hdf5\n",
      "dataset_filter_key: g40f10s10\n",
      "fn_seg: /home/ns1254/dataset_mimicgen/square_bad_segs_0ind.txt\n",
      "data: {\"demo_14\": [[0, 621]], \"demo_21\": [[0, 612]], \"demo_23\": [[0, 598]], \"demo_24\": [[0, 997]], \"demo_39\": [[0, 634]], \"demo_42\": [[0, 846]], \"demo_4\": [[0, 654]], \"demo_49\": [[0, 517]], \"demo_50\": [[0, 713]], \"demo_58\": [[0, 527]], \"demo_10\": [[200, 488]], \"demo_12\": [[164, 602]], \"demo_19\": [[177, 979]], \"demo_20\": [[162, 673]], \"demo_26\": [[211, 662]], \"demo_28\": [[218, 1120]], \"demo_2\": [[199, 730]], \"demo_31\": [[166, 753]], \"demo_33\": [[191, 968]], \"demo_34\": [[171, 1134]]}\n"
     ]
    }
   ],
   "source": [
    "with open('/home/ns1254/gib/segs/segs_square_g40f10s10.txt', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "segs_todo= data['segs_todo']\n",
    "dataset_path = data['dataset_path']\n",
    "dataset_filter_key = data['dataset_filter_key']\n",
    "fn_seg = data['fn_seg']\n",
    "data = data['data']\n",
    "segs_toremove=json.loads(data)\n",
    "\n",
    "print(f\"segs_todo: {segs_todo}\")\n",
    "print(f\"dataset_path: {dataset_path}\")\n",
    "print(f\"dataset_filter_key: {dataset_filter_key}\")\n",
    "print(f\"fn_seg: {fn_seg}\") \n",
    "print(f\"data: {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['demo_14', 'demo_21', 'demo_23']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list( segs_toremove.keys() )[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/home/ns1254/dataset_mimicgen/square134_2_0ind_abs.hdf5\" \n",
    "# dataset_filter_key = \"g40b30\"\n",
    "config_path='equi_diffpo/config' \n",
    "config_name = 'train_diffusion_unet.yaml'\n",
    "task_name='square_d2' \n",
    "n_demo = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'diff_c', '_target_': 'equi_diffpo.workspace.train_diffusion_unet_hybrid_workspace.TrainDiffusionUnetHybridWorkspace', 'shape_meta': '${task.shape_meta}', 'exp_name': 'default', 'task_name': 'square_d2', 'n_demo': 100, 'horizon': 16, 'n_obs_steps': 2, 'n_action_steps': 8, 'n_latency_steps': 0, 'dataset_obs_steps': '${n_obs_steps}', 'past_action_visible': False, 'obs_as_global_cond': True, 'dataset': 'equi_diffpo.dataset.robomimic_replay_image_dataset.RobomimicReplayImageDataset', 'dataset_path': 'data/robomimic/datasets/${task_name}/${task_name}_abs.hdf5', 'dataset_filter_key': 'all', 'policy': {'_target_': 'equi_diffpo.policy.diffusion_unet_hybrid_image_policy.DiffusionUnetHybridImagePolicy', 'shape_meta': '${shape_meta}', 'noise_scheduler': {'_target_': 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler', 'num_train_timesteps': 100, 'beta_start': 0.0001, 'beta_end': 0.02, 'beta_schedule': 'squaredcos_cap_v2', 'variance_type': 'fixed_small', 'clip_sample': True, 'prediction_type': 'epsilon'}, 'horizon': '${horizon}', 'n_action_steps': \"${eval:'${n_action_steps}+${n_latency_steps}'}\", 'n_obs_steps': '${n_obs_steps}', 'num_inference_steps': 100, 'obs_as_global_cond': '${obs_as_global_cond}', 'crop_shape': [76, 76], 'diffusion_step_embed_dim': 128, 'down_dims': [512, 1024, 2048], 'kernel_size': 5, 'n_groups': 8, 'cond_predict_scale': True, 'obs_encoder_group_norm': True, 'eval_fixed_crop': True, 'rot_aug': False}, 'ema': {'_target_': 'equi_diffpo.model.diffusion.ema_model.EMAModel', 'update_after_step': 0, 'inv_gamma': 1.0, 'power': 0.75, 'min_value': 0.0, 'max_value': 0.9999}, 'dataloader': {'batch_size': 64, 'num_workers': 4, 'shuffle': True, 'pin_memory': True, 'persistent_workers': True}, 'val_dataloader': {'batch_size': 64, 'num_workers': 4, 'shuffle': False, 'pin_memory': True, 'persistent_workers': True}, 'optimizer': {'_target_': 'torch.optim.AdamW', 'lr': 0.0001, 'betas': [0.95, 0.999], 'eps': 1e-08, 'weight_decay': 1e-06}, 'training': {'device': 'cuda:0', 'seed': 0, 'debug': False, 'resume': True, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 500, 'num_epochs': \"${eval:'50000 / ${n_demo}'}\", 'gradient_accumulate_every': 1, 'use_ema': True, 'rollout_every': \"${eval:'1000 / ${n_demo}'}\", 'checkpoint_every': \"${eval:'1000 / ${n_demo}'}\", 'val_every': 1, 'sample_every': 5, 'max_train_steps': None, 'max_val_steps': None, 'tqdm_interval_sec': 1.0}, 'logging': {'project': 'diffusion_policy_${task_name}', 'resume': True, 'mode': 'online', 'name': 'diff_c_demo${n_demo}', 'tags': ['${name}', '${task_name}', '${exp_name}'], 'id': None, 'group': None}, 'checkpoint': {'topk': {'monitor_key': 'test_mean_score', 'mode': 'max', 'k': 5, 'format_str': 'epoch={epoch:04d}-test_mean_score={test_mean_score:.3f}.ckpt'}, 'save_last_ckpt': True, 'save_last_snapshot': False}, 'multi_run': {'run_dir': 'data/outputs/${now:%Y.%m.%d}/${now:%H.%M.%S}_${name}_${task_name}', 'wandb_name_base': '${now:%Y.%m.%d-%H.%M.%S}_${name}_${task_name}'}, 'task': {'name': 'mimicgen_abs', 'shape_meta': {'obs': {'agentview_image': {'shape': [3, 84, 84], 'type': 'rgb'}, 'robot0_eye_in_hand_image': {'shape': [3, 84, 84], 'type': 'rgb'}, 'robot0_eef_pos': {'shape': [3]}, 'robot0_eef_quat': {'shape': [4]}, 'robot0_gripper_qpos': {'shape': [2]}}, 'action': {'shape': [10]}}, 'abs_action': True, 'env_runner': {'_target_': 'equi_diffpo.env_runner.robomimic_image_runner.RobomimicImageRunner', 'dataset_path': '${dataset_path}', 'shape_meta': {'obs': {'agentview_image': {'shape': [3, 84, 84], 'type': 'rgb'}, 'robot0_eye_in_hand_image': {'shape': [3, 84, 84], 'type': 'rgb'}, 'robot0_eef_pos': {'shape': [3]}, 'robot0_eef_quat': {'shape': [4]}, 'robot0_gripper_qpos': {'shape': [2]}}, 'action': {'shape': [10]}}, 'n_train': 6, 'n_train_vis': 2, 'train_start_idx': 0, 'n_test': 50, 'n_test_vis': 4, 'test_start_seed': 100000, 'max_steps': '${get_max_steps:${task_name}}', 'n_obs_steps': '${n_obs_steps}', 'n_action_steps': '${n_action_steps}', 'render_obs_key': 'agentview_image', 'fps': 10, 'crf': 22, 'past_action': '${past_action_visible}', 'abs_action': True, 'tqdm_interval_sec': 1.0, 'n_envs': 28}, 'dataset': {'_target_': '${dataset}', 'n_demo': '${n_demo}', 'shape_meta': {'obs': {'agentview_image': {'shape': [3, 84, 84], 'type': 'rgb'}, 'robot0_eye_in_hand_image': {'shape': [3, 84, 84], 'type': 'rgb'}, 'robot0_eef_pos': {'shape': [3]}, 'robot0_eef_quat': {'shape': [4]}, 'robot0_gripper_qpos': {'shape': [2]}}, 'action': {'shape': [10]}}, 'dataset_path': '${dataset_path}', 'dataset_filter_key': '${dataset_filter_key}', 'horizon': '${horizon}', 'pad_before': \"${eval:'${n_obs_steps}-1+${n_latency_steps}'}\", 'pad_after': \"${eval:'${n_action_steps}-1'}\", 'n_obs_steps': '${dataset_obs_steps}', 'abs_action': True, 'rotation_rep': 'rotation_6d', 'use_legacy_normalizer': False, 'use_cache': True, 'seed': 42, 'val_ratio': 0.02}}}\n"
     ]
    }
   ],
   "source": [
    "with initialize(version_base=None, config_path=config_path):\n",
    "    cfg_org = compose(\n",
    "        config_name=config_name,\n",
    "        overrides=[ \n",
    "            f\"task_name={task_name}\",\n",
    "            f\"n_demo={n_demo}\"\n",
    "        ],\n",
    "    )\n",
    "    print(cfg_org)\n",
    "    \n",
    "OmegaConf.resolve(cfg_org) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "equi_diffpo.workspace.train_diffusion_unet_hybrid_workspace.TrainDiffusionUnetHybridWorkspace"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = hydra.utils.get_class(cfg_org._target_)\n",
    "cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['name', '_target_', 'shape_meta', 'exp_name', 'task_name', 'n_demo', 'horizon', 'n_obs_steps', 'n_action_steps', 'n_latency_steps', 'dataset_obs_steps', 'past_action_visible', 'obs_as_global_cond', 'dataset', 'dataset_path', 'dataset_filter_key', 'policy', 'ema', 'dataloader', 'val_dataloader', 'optimizer', 'training', 'logging', 'checkpoint', 'multi_run', 'task'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_org.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDiffusionUnetHybridWorkspace(BaseWorkspace):\n",
    "    include_keys = ['global_step', 'epoch']\n",
    "\n",
    "    def __init__(self, cfg: OmegaConf, output_dir=None):\n",
    "        super().__init__(cfg, output_dir=output_dir)\n",
    "\n",
    "        # set seed\n",
    "        seed = cfg.training.seed\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        # configure model\n",
    "        self.model: DiffusionUnetHybridImagePolicy = hydra.utils.instantiate(cfg.policy)\n",
    "\n",
    "        self.ema_model: DiffusionUnetHybridImagePolicy = None\n",
    "        if cfg.training.use_ema:\n",
    "            self.ema_model = copy.deepcopy(self.model)\n",
    "\n",
    "        # configure training state\n",
    "        self.optimizer = hydra.utils.instantiate(\n",
    "            cfg.optimizer, params=self.model.parameters())\n",
    "\n",
    "        # configure training state\n",
    "        self.global_step = 0\n",
    "        self.epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============= Initialized Observation Utils with Obs Spec =============\n",
      "\n",
      "using obs modality: low_dim with keys: ['robot0_gripper_qpos', 'robot0_eef_pos', 'robot0_eef_quat']\n",
      "using obs modality: rgb with keys: ['agentview_image', 'robot0_eye_in_hand_image']\n",
      "using obs modality: depth with keys: []\n",
      "using obs modality: scan with keys: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ns1254/miniconda3/envs/equidiff/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ns1254/miniconda3/envs/equidiff/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusion params: 2.556120e+08\n",
      "Vision params: 2.239418e+07\n"
     ]
    }
   ],
   "source": [
    "output_dir = f\"/home/ns1254/equidiff/outputs/square_{now}\"\n",
    "# os.mkdir(output_dir)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "workspace = TrainDiffusionUnetHybridWorkspace(cfg_org, output_dir=output_dir)\n",
    "\n",
    "self = workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = copy.deepcopy(self.cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('_target_', 'equi_diffpo.dataset.robomimic_replay_image_dataset.RobomimicReplayImageDataset'), ('n_demo', 100), ('shape_meta', {'obs': {'agentview_image': {'shape': [3, 84, 84], 'type': 'rgb'}, 'robot0_eye_in_hand_image': {'shape': [3, 84, 84], 'type': 'rgb'}, 'robot0_eef_pos': {'shape': [3]}, 'robot0_eef_quat': {'shape': [4]}, 'robot0_gripper_qpos': {'shape': [2]}}, 'action': {'shape': [10]}}), ('dataset_path', 'data/robomimic/datasets/square_d2/square_d2_abs.hdf5'), ('dataset_filter_key', 'all'), ('horizon', 16), ('pad_before', 1), ('pad_after', 7), ('n_obs_steps', 2), ('abs_action', True), ('rotation_rep', 'rotation_6d'), ('use_legacy_normalizer', False), ('use_cache', True), ('seed', 42), ('val_ratio', 0.02)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.task.dataset.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "dataset_path:  /home/ns1254/dataset_mimicgen/square134_2_0ind_abs.hdf5\n",
      "dataset filter key:  g40f10s10\n",
      "----------------------------\n",
      "------------------------------ self.n_demo=60------------------------------\n",
      "Acquiring lock on cache.\n",
      "Loading cached ReplayBuffer from Disk.\n",
      "Loaded!\n"
     ]
    }
   ],
   "source": [
    "# resume training\n",
    "# if cfg.training.resume:\n",
    "#     lastest_ckpt_path = self.get_checkpoint_path()\n",
    "#     if lastest_ckpt_path.is_file():\n",
    "#         print(f\"Resuming from checkpoint {lastest_ckpt_path}\")\n",
    "#         self.load_checkpoint(path=lastest_ckpt_path)\n",
    "  \n",
    "new_config = {key: value for key, value in cfg.task.dataset.items() if key != '_target_'}\n",
    "new_config['dataset_path'] = dataset_path\n",
    "new_config['dataset_filter_key'] = dataset_filter_key\n",
    "\n",
    "del new_config[\"n_demo\"]\n",
    "\n",
    "\n",
    "obs_shape_meta_config = {key: value for key, value in new_config['shape_meta']['obs'].items()}\n",
    "obs_shape_meta_config['demo_no'] = {'shape': [], 'type': 'low_dim'}\n",
    "obs_shape_meta_config['index_in_demo'] = {'shape': [], 'type': 'low_dim'}\n",
    "\n",
    "new_config['shape_meta']['obs'] = obs_shape_meta_config\n",
    "\n",
    "\n",
    "dataset = RobomimicReplayImageDataset(**new_config )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agentview_image': {'shape': [3, 84, 84], 'type': 'rgb'},\n",
       " 'robot0_eye_in_hand_image': {'shape': [3, 84, 84], 'type': 'rgb'},\n",
       " 'robot0_eef_pos': {'shape': [3]},\n",
       " 'robot0_eef_quat': {'shape': [4]},\n",
       " 'robot0_gripper_qpos': {'shape': [2]},\n",
       " 'demo_no': {'shape': [], 'type': 'low_dim'},\n",
       " 'index_in_demo': {'shape': [], 'type': 'low_dim'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_shape_meta_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agentview_image {'shape': [3, 84, 84], 'type': 'rgb'}\n",
      "robot0_eye_in_hand_image {'shape': [3, 84, 84], 'type': 'rgb'}\n",
      "robot0_eef_pos {'shape': [3]}\n",
      "robot0_eef_quat {'shape': [4]}\n",
      "robot0_gripper_qpos {'shape': [2]}\n",
      "demo_no {'shape': [], 'type': 'low_dim'}\n",
      "index_in_demo {'shape': [], 'type': 'low_dim'}\n"
     ]
    }
   ],
   "source": [
    "for key in new_config['shape_meta']['obs']:\n",
    "    print(key, new_config['shape_meta']['obs'][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = dataset.sampler.sample_sequence(index)\n",
    "# data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['obs', 'action'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=10\n",
    "data = dataset.__getitem__(index)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['agentview_image', 'robot0_eye_in_hand_image', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos', 'demo_no', 'index_in_demo'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['obs'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 84, 84])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['obs']['agentview_image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_1_data(data):\n",
    "    \"\"\" \n",
    "    data: at time t from dataset.\n",
    "    #each timestamp can contain multiple uid because of obs_horizon\n",
    "    \"\"\"\n",
    "    if 'demo_no' not in data['obs']:\n",
    "        raise Exception(\"Please add demo_no and index_in_demo to the obs first.\")\n",
    "    \n",
    "    demo_nos = data['obs']['demo_no']\n",
    "    indices_in_demo = data['obs']['index_in_demo']\n",
    "    return demo_nos, indices_in_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segs_toremove={\n",
    "#  'demo_0': [ (5,20), (30, 40) ],\n",
    "#  'demo_1': [ (12, 20) ],\n",
    "#  'demo_12': [(0, 10), (15, 20), (30,33) ],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_ids={}\n",
    "for key in segs_toremove.keys():\n",
    "    segs = segs_toremove[key]\n",
    "    ids = [] \n",
    "    for start, end in segs:\n",
    "        ids.extend(range(start, end + 1))  # Include the end value\n",
    "    remove_ids[key]=ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60207/60207 [08:07<00:00, 123.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(47278, 60207)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_indices =[]  #in the dataset.\n",
    "\n",
    "for index in tqdm( range(len(dataset)) ):\n",
    "    data = dataset.__getitem__(index)\n",
    "    demo_no, indices_in_demo = parse_1_data(data) \n",
    "\n",
    "    assert torch.all( demo_no[0]==demo_no[1] )                 #obs history from same demo\n",
    "    demo_name=f'demo_{int(demo_no[0])}'\n",
    "    ids = indices_in_demo.numpy().astype(int)\n",
    "    \n",
    "    should_remove = False\n",
    "    if demo_name in remove_ids:\n",
    "        should_remove = bool(set(remove_ids[demo_name]) & set(ids))\n",
    "    if should_remove: continue \n",
    "    valid_indices.append(index)\n",
    "\n",
    "len(valid_indices), len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('demo_99', array([346, 347]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_name, indices_in_demo.numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.lowdim_keys.remove('demo_no')\n",
    "# dataset.lowdim_keys.remove('index_in_demo')  # remove the added helper keys (demo_no and index in demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['robot0_eef_pos',\n",
       " 'robot0_eef_quat',\n",
       " 'robot0_gripper_qpos',\n",
       " 'demo_no',\n",
       " 'index_in_demo']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.lowdim_keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomIndicesSampler(Sampler):\n",
    "    def __init__(self, custom_indices):\n",
    "        self.custom_indices = np.random.permutation(custom_indices)\n",
    "\n",
    "    def __iter__(self): \n",
    "        return iter(self.custom_indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len( self.custom_indices )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = CustomIndicesSampler(valid_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 64, 'num_workers': 4, 'shuffle': True, 'pin_memory': True, 'persistent_workers': True}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_config = {key:value for key,value in cfg.dataloader.items()}\n",
    "new_config['shuffle'] = False\n",
    "new_config['sampler'] = sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 64,\n",
       " 'num_workers': 4,\n",
       " 'shuffle': False,\n",
       " 'pin_memory': True,\n",
       " 'persistent_workers': True,\n",
       " 'sampler': <__main__.CustomIndicesSampler at 0x7fba3473b430>}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: train and validation need to be handled for partial trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset, **new_config)\n",
    "# \n",
    "# normalizer = dataset.get_normalizer()\n",
    "\n",
    "# configure validation dataset\n",
    "val_dataset = dataset.get_validation_dataset()\n",
    "val_dataloader = DataLoader(val_dataset, **cfg.val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checking progress: 100%|██████████| 739/739 [01:33<00:00,  7.87batch/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(train_dataloader, desc=\"checking progress\", unit=\"batch\"):    \n",
    "    obs=batch['obs']\n",
    "    demo_no=batch['obs']['demo_no']\n",
    "    index_in_demo=batch['obs']['index_in_demo']\n",
    "\n",
    "    assert torch.all( demo_no[:,0]==demo_no[:,1] )                    #obs history from same demo\n",
    "    demo_names=[f'demo_{int(i)}' for i in demo_no[:,0]]\n",
    "\n",
    "    for demo_name, index in zip(demo_names, index_in_demo):\n",
    "        i,j= int( index[0].item() ), int( index[1].item() )\n",
    "        # print(demo_name, i, j)\n",
    "        if demo_name in segs_toremove:\n",
    "            for s,e in segs_toremove[demo_name]: \n",
    "                if s<=i<=e or s<=j<=e:                          #i and j within start-end\n",
    "                    print(f\"should remove {demo_name} {i} {j}\")\n",
    "                    break\n",
    "\n",
    "\n",
    "    # break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "739"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47278"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( train_dataloader.sampler )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checking progress: 100%|██████████| 15/15 [00:18<00:00,  1.26s/batch]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(val_dataloader, desc=\"checking progress\", unit=\"batch\"):\n",
    "    obs=batch['obs']\n",
    "    demo_no=batch['obs']['demo_no']\n",
    "    index_in_demo=batch['obs']['index_in_demo']\n",
    "\n",
    "    assert torch.all( demo_no[:,0]==demo_no[:,1] )                    #obs history from same demo\n",
    "    demo_names=[f'demo_{int(i)}' for i in demo_no[:,0]]\n",
    "\n",
    "    for demo_name, index in zip(demo_names, index_in_demo):\n",
    "        i,j= int( index[0].item() ), int( index[1].item() )\n",
    "        # print(demo_name, i, j)\n",
    "        if demo_name in segs_toremove:\n",
    "            for s,e in segs_toremove[demo_name]: \n",
    "                if s<=i<=e or s<=j<=e:                          #i and j within start-end\n",
    "                    print(f\"should remove {demo_name} {i} {j}\")\n",
    "                    break\n",
    "\n",
    "\n",
    "    # break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "equidiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
