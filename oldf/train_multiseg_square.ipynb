{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/ubuntu/mimicgen/envs/robosuite/robosuite/scripts/setup_macros.py (macros.py:55)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: robosuite task zoo environments not imported, possibly because robosuite_task_zoo is not installed...\n",
      "Got error: No module named 'robosuite_task_zoo'\n",
      "\u001b[33mROBOMIMIC WARNING(\n",
      "    No private macro file found!\n",
      "    It is recommended to use a private macro file\n",
      "    To setup, run: python /home/ubuntu/mimicgen/envs/robomimic/robomimic/scripts/setup_macros.py\n",
      ")\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import psutil\n",
    "import sys\n",
    "import socket\n",
    "import traceback\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import mimicgen\n",
    "import robomimic\n",
    "import robomimic.utils.train_utils as TrainUtils\n",
    "import robomimic.utils.torch_utils as TorchUtils\n",
    "import robomimic.utils.obs_utils as ObsUtils\n",
    "import robomimic.utils.env_utils as EnvUtils\n",
    "import robomimic.utils.file_utils as FileUtils\n",
    "from robomimic.config import config_factory\n",
    "from robomimic.algo import algo_factory, RolloutPolicy\n",
    "from robomimic.utils.log_utils import PrintLogger, DataLogger, flush_warnings\n",
    "\n",
    "import h5py\n",
    " \n",
    "import mimicgen.utils.file_utils as MG_FileUtils\n",
    "import mimicgen.utils.robomimic_utils as RobomimicUtils\n",
    "from mimicgen.utils.misc_utils import add_red_border_to_frame\n",
    "from mimicgen.configs import MG_TaskSpec\n",
    "\n",
    "from dataset_mod_seg import MultiSegmentSequenceDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"/home/ubuntu/bc_trans124.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config_file:  /home/ubuntu/bc_trans124.json\n",
      "data file:  /home/ubuntu/dataset_mimicgen/square134_2_0ind.hdf5\n",
      "device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "ext_cfg = json.load(open(config_file, 'r'))\n",
    "config = config_factory(ext_cfg[\"algo_name\"])\n",
    "# update config with external json - this will throw errors if\n",
    "# the external config has keys not present in the base algo config\n",
    "with config.values_unlocked():\n",
    "    config.update(ext_cfg)\n",
    "config.lock()\n",
    "\n",
    "device = TorchUtils.get_torch_device(try_to_use_cuda=config.train.cuda)\n",
    "\n",
    "print('config_file: ', config_file)\n",
    "print('data file: ', config.train.data) \n",
    "print('device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============= Initialized Observation Utils with Obs Spec =============\n",
      "\n",
      "using obs modality: low_dim with keys: ['robot0_eef_pos', 'robot0_gripper_qpos', 'robot0_eef_quat']\n",
      "using obs modality: rgb with keys: ['agentview_image', 'robot0_eye_in_hand_image']\n",
      "using obs modality: depth with keys: []\n",
      "using obs modality: scan with keys: []\n",
      "obs key agentview_image with shape (84, 84, 3)\n",
      "obs key robot0_eef_pos with shape (3,)\n",
      "obs key robot0_eef_quat with shape (4,)\n",
      "obs key robot0_eye_in_hand_image with shape (84, 84, 3)\n",
      "obs key robot0_gripper_qpos with shape (2,)\n"
     ]
    }
   ],
   "source": [
    "# first set seeds\n",
    "np.random.seed(config.train.seed)\n",
    "torch.manual_seed(config.train.seed)\n",
    "\n",
    "# torch.set_num_threads(2)\n",
    "\n",
    "# read config to set up metadata for observation modalities (e.g. detecting rgb observations)\n",
    "ObsUtils.initialize_obs_utils_with_config(config)\n",
    "\n",
    "# make sure the dataset exists\n",
    "dataset_path = os.path.expanduser(config.train.data)\n",
    "if not os.path.exists(dataset_path):\n",
    "    raise Exception(\"Dataset at provided path {} not found!\".format(dataset_path))\n",
    " \n",
    "env_meta = FileUtils.get_env_metadata_from_dataset(dataset_path=config.train.data)\n",
    "shape_meta = FileUtils.get_shape_metadata_from_dataset(\n",
    "    dataset_path=config.train.data,\n",
    "    all_obs_keys=config.all_obs_keys,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path=config.train.data\n",
    "file=h5py.File(data_path, 'r')\n",
    "demos=file['data'].keys()\n",
    "# demos=[b.decode('utf-8') for b in file['mask'][config.train.hdf5_filter_key]]\n",
    "\n",
    "segs_orginal={}\n",
    "for demo in demos: \n",
    "    segs_orginal[demo]=[ [0, file['data'][demo].attrs['num_samples']-1]  ]\n",
    "\n",
    "file.close()\n",
    "len(segs_orginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subtasks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"/home/ubuntu/mimicgen/configs/core_configs/demo_src_square_task_D0.json\"\n",
    "dataset_path = config.train.data\n",
    "filter_key = config.train.hdf5_filter_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using filter key: g40b30\n"
     ]
    }
   ],
   "source": [
    "demo_keys = MG_FileUtils.get_all_demos_from_dataset(\n",
    "    dataset_path=dataset_path,\n",
    "    filter_key= filter_key,\n",
    "    start=None,\n",
    "    n=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_spec = None\n",
    "subtask_term_signals = None\n",
    "subtask_term_offset_ranges = None\n",
    "\n",
    "with open(config_path, 'r') as f_config:\n",
    "    mg_config = json.load(f_config)\n",
    "task_spec = MG_TaskSpec.from_json(json_dict=mg_config[\"task\"][\"task_spec\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:00<00:00, 588.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# parse dataset to get subtask boundaries\n",
    "_, subtask_indices, _, subtask_term_offset_ranges_ret = MG_FileUtils.parse_source_dataset(\n",
    "    dataset_path=dataset_path,\n",
    "    demo_keys=demo_keys,\n",
    "    task_spec=task_spec,\n",
    "    subtask_term_signals=subtask_term_signals,\n",
    "    subtask_term_offset_ranges=subtask_term_offset_ranges,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(demo_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtask_indices2={demo_keys[i]:subtask_indices[i] for i in range(len(demo_keys))}\n",
    "len(subtask_indices2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g40b30'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.train.hdf5_filter_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_seg=\"square_124_60.txt\"\n",
    "\n",
    "with open(fn_seg, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    lines=[line.strip() for line in lines]\n",
    "\n",
    "multi_seg={}\n",
    "for line in lines:\n",
    "    seg = line.split(\": \")\n",
    "    demo = seg[0].strip()\n",
    "    segs= seg[1].strip()\n",
    "    multi_seg[demo] = segs\n",
    "\n",
    "\n",
    "segments_map_bad={}\n",
    "\n",
    "for key in multi_seg.keys():\n",
    "    map=multi_seg[key]\n",
    "    segments_map_bad[key]=[]\n",
    "    ind=int(key.split(\"_\")[1])\n",
    "    # segs=subtask_indices[ind]\n",
    "    segs=subtask_indices2[key]\n",
    "    for i in range(len(map)): \n",
    "        if map[i] == 'g': \n",
    "            # segments_map_bad[key].append( list(segs[i]) )\n",
    "            segments_map_bad[key].append( (segs[i][0], segs[i][1]-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'demo_1': [(np.int64(0), np.int64(152))],\n",
       " 'demo_2': [(np.int64(199), np.int64(730))],\n",
       " 'demo_3': []}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments_map_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_map={}\n",
    "for key in segs_orginal.keys():\n",
    "    if key in segments_map_bad.keys():\n",
    "        segments_map[key]=segments_map_bad[key]\n",
    "    else:\n",
    "        segments_map[key]=segs_orginal[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'demo_0': [[0, np.int64(332)]],\n",
       " 'demo_1': [(np.int64(0), np.int64(152))],\n",
       " 'demo_10': [[0, np.int64(488)]],\n",
       " 'demo_100': [[0, np.int64(538)]],\n",
       " 'demo_101': [[0, np.int64(790)]],\n",
       " 'demo_102': [[0, np.int64(701)]],\n",
       " 'demo_103': [[0, np.int64(644)]],\n",
       " 'demo_104': [[0, np.int64(590)]],\n",
       " 'demo_105': [[0, np.int64(469)]],\n",
       " 'demo_106': [[0, np.int64(715)]],\n",
       " 'demo_107': [[0, np.int64(624)]],\n",
       " 'demo_108': [[0, np.int64(544)]],\n",
       " 'demo_109': [[0, np.int64(686)]],\n",
       " 'demo_11': [[0, np.int64(780)]],\n",
       " 'demo_110': [[0, np.int64(684)]],\n",
       " 'demo_111': [[0, np.int64(1083)]],\n",
       " 'demo_112': [[0, np.int64(727)]],\n",
       " 'demo_113': [[0, np.int64(766)]],\n",
       " 'demo_114': [[0, np.int64(489)]],\n",
       " 'demo_115': [[0, np.int64(485)]],\n",
       " 'demo_116': [[0, np.int64(551)]],\n",
       " 'demo_117': [[0, np.int64(693)]],\n",
       " 'demo_118': [[0, np.int64(820)]],\n",
       " 'demo_119': [[0, np.int64(1031)]],\n",
       " 'demo_12': [[0, np.int64(602)]],\n",
       " 'demo_120': [[0, np.int64(627)]],\n",
       " 'demo_121': [[0, np.int64(495)]],\n",
       " 'demo_122': [[0, np.int64(572)]],\n",
       " 'demo_123': [[0, np.int64(585)]],\n",
       " 'demo_124': [[0, np.int64(575)]],\n",
       " 'demo_125': [[0, np.int64(610)]],\n",
       " 'demo_126': [[0, np.int64(1122)]],\n",
       " 'demo_127': [[0, np.int64(438)]],\n",
       " 'demo_128': [[0, np.int64(625)]],\n",
       " 'demo_129': [[0, np.int64(456)]],\n",
       " 'demo_13': [[0, np.int64(993)]],\n",
       " 'demo_14': [[0, np.int64(830)]],\n",
       " 'demo_15': [[0, np.int64(375)]],\n",
       " 'demo_16': [[0, np.int64(383)]],\n",
       " 'demo_17': [[0, np.int64(416)]],\n",
       " 'demo_18': [[0, np.int64(413)]],\n",
       " 'demo_19': [[0, np.int64(979)]],\n",
       " 'demo_2': [(np.int64(199), np.int64(730))],\n",
       " 'demo_20': [[0, np.int64(673)]],\n",
       " 'demo_21': [[0, np.int64(836)]],\n",
       " 'demo_22': [[0, np.int64(376)]],\n",
       " 'demo_23': [[0, np.int64(822)]],\n",
       " 'demo_24': [[0, np.int64(1143)]],\n",
       " 'demo_25': [[0, np.int64(617)]],\n",
       " 'demo_26': [[0, np.int64(662)]],\n",
       " 'demo_27': [[0, np.int64(1014)]],\n",
       " 'demo_28': [[0, np.int64(1120)]],\n",
       " 'demo_29': [[0, np.int64(447)]],\n",
       " 'demo_3': [],\n",
       " 'demo_30': [[0, np.int64(393)]],\n",
       " 'demo_31': [[0, np.int64(753)]],\n",
       " 'demo_32': [[0, np.int64(932)]],\n",
       " 'demo_33': [[0, np.int64(968)]],\n",
       " 'demo_34': [[0, np.int64(1134)]],\n",
       " 'demo_35': [[0, np.int64(735)]],\n",
       " 'demo_36': [[0, np.int64(594)]],\n",
       " 'demo_37': [[0, np.int64(329)]],\n",
       " 'demo_38': [[0, np.int64(388)]],\n",
       " 'demo_39': [[0, np.int64(882)]],\n",
       " 'demo_4': [[0, np.int64(816)]],\n",
       " 'demo_40': [[0, np.int64(451)]],\n",
       " 'demo_41': [[0, np.int64(435)]],\n",
       " 'demo_42': [[0, np.int64(1005)]],\n",
       " 'demo_43': [[0, np.int64(501)]],\n",
       " 'demo_44': [[0, np.int64(931)]],\n",
       " 'demo_45': [[0, np.int64(648)]],\n",
       " 'demo_46': [[0, np.int64(357)]],\n",
       " 'demo_47': [[0, np.int64(359)]],\n",
       " 'demo_48': [[0, np.int64(451)]],\n",
       " 'demo_49': [[0, np.int64(704)]],\n",
       " 'demo_5': [[0, np.int64(412)]],\n",
       " 'demo_50': [[0, np.int64(875)]],\n",
       " 'demo_51': [[0, np.int64(675)]],\n",
       " 'demo_52': [[0, np.int64(400)]],\n",
       " 'demo_53': [[0, np.int64(901)]],\n",
       " 'demo_54': [[0, np.int64(926)]],\n",
       " 'demo_55': [[0, np.int64(547)]],\n",
       " 'demo_56': [[0, np.int64(374)]],\n",
       " 'demo_57': [[0, np.int64(1000)]],\n",
       " 'demo_58': [[0, np.int64(775)]],\n",
       " 'demo_59': [[0, np.int64(1083)]],\n",
       " 'demo_6': [[0, np.int64(1102)]],\n",
       " 'demo_60': [[0, np.int64(417)]],\n",
       " 'demo_61': [[0, np.int64(397)]],\n",
       " 'demo_62': [[0, np.int64(347)]],\n",
       " 'demo_63': [[0, np.int64(378)]],\n",
       " 'demo_64': [[0, np.int64(832)]],\n",
       " 'demo_65': [[0, np.int64(412)]],\n",
       " 'demo_66': [[0, np.int64(752)]],\n",
       " 'demo_67': [[0, np.int64(373)]],\n",
       " 'demo_68': [[0, np.int64(707)]],\n",
       " 'demo_69': [[0, np.int64(970)]],\n",
       " 'demo_7': [[0, np.int64(861)]],\n",
       " 'demo_70': [[0, np.int64(352)]],\n",
       " 'demo_71': [[0, np.int64(544)]],\n",
       " 'demo_72': [[0, np.int64(404)]],\n",
       " 'demo_73': [[0, np.int64(425)]],\n",
       " 'demo_74': [[0, np.int64(1014)]],\n",
       " 'demo_75': [[0, np.int64(395)]],\n",
       " 'demo_76': [[0, np.int64(1227)]],\n",
       " 'demo_77': [[0, np.int64(365)]],\n",
       " 'demo_78': [[0, np.int64(384)]],\n",
       " 'demo_79': [[0, np.int64(367)]],\n",
       " 'demo_8': [[0, np.int64(598)]],\n",
       " 'demo_80': [[0, np.int64(332)]],\n",
       " 'demo_81': [[0, np.int64(831)]],\n",
       " 'demo_82': [[0, np.int64(661)]],\n",
       " 'demo_83': [[0, np.int64(648)]],\n",
       " 'demo_84': [[0, np.int64(411)]],\n",
       " 'demo_85': [[0, np.int64(380)]],\n",
       " 'demo_86': [[0, np.int64(354)]],\n",
       " 'demo_87': [[0, np.int64(984)]],\n",
       " 'demo_88': [[0, np.int64(427)]],\n",
       " 'demo_89': [[0, np.int64(531)]],\n",
       " 'demo_9': [[0, np.int64(373)]],\n",
       " 'demo_90': [[0, np.int64(394)]],\n",
       " 'demo_91': [[0, np.int64(408)]],\n",
       " 'demo_92': [[0, np.int64(387)]],\n",
       " 'demo_93': [[0, np.int64(544)]],\n",
       " 'demo_94': [[0, np.int64(366)]],\n",
       " 'demo_95': [[0, np.int64(743)]],\n",
       " 'demo_96': [[0, np.int64(392)]],\n",
       " 'demo_97': [[0, np.int64(552)]],\n",
       " 'demo_98': [[0, np.int64(384)]],\n",
       " 'demo_99': [[0, np.int64(354)]]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=config.train.data\n",
    "obs_keys=shape_meta[\"all_obs_keys\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80661"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_kwargs = dict(\n",
    "    hdf5_path=data_path,\n",
    "    obs_keys=obs_keys,\n",
    "    dataset_keys=['actions'], \n",
    "    frame_stack=10,   \n",
    "    seq_length=1,\n",
    "    segments_map=segments_map,     # new parameter\n",
    "    pad_frame_stack=True,\n",
    "    pad_seq_length=True,\n",
    "    get_pad_mask=False, \n",
    "    hdf5_cache_mode= None, #'low_dim', #'all',\n",
    "    hdf5_use_swmr=True \n",
    ")\n",
    "\n",
    "trainset=MultiSegmentSequenceDataset(**ds_kwargs)\n",
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_sequences=45682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.experiment.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STDOUT will be forked to /home/ubuntu/mimicgen/mimicgen/../training_results/core/square/image/trained_models/square/20250430085513/logs/log.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libEGL warning: MESA-LOADER: failed to open virtio_gpu: /usr/lib/dri/virtio_gpu_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: NEEDS EXTENSION: falling back to kms_swrast\n",
      "libEGL warning: MESA-LOADER: failed to open kms_swrast: /usr/lib/dri/kms_swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Cannot initialize a EGL device display. This likely means that your EGL driver does not support the PLATFORM_DEVICE extension, which is required for creating a headless rendering context.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m         env_names.append(name)\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m env_name \u001b[38;5;129;01min\u001b[39;00m env_names:\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     env = \u001b[43mEnvUtils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_env_from_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43menv_meta\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv_meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43menv_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrender\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrender_offscreen\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender_video\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_image_obs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshape_meta\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muse_images\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     env = EnvUtils.wrap_env_from_config(env, config=config) \u001b[38;5;66;03m# apply environment warpper, if applicable\u001b[39;00m\n\u001b[32m     28\u001b[39m     envs[env.name] = env\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mimicgen/envs/robomimic/robomimic/utils/env_utils.py:229\u001b[39m, in \u001b[36mcreate_env_from_metadata\u001b[39m\u001b[34m(env_meta, env_name, render, render_offscreen, use_image_obs, use_depth_obs)\u001b[39m\n\u001b[32m    226\u001b[39m env_type = get_env_type(env_meta=env_meta)\n\u001b[32m    227\u001b[39m env_kwargs = env_meta[\u001b[33m\"\u001b[39m\u001b[33menv_kwargs\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m env = \u001b[43mcreate_env\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[43menv_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m    \u001b[49m\u001b[43menv_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrender\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrender_offscreen\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrender_offscreen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_image_obs\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_image_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_depth_obs\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_depth_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43menv_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m check_env_version(env, env_meta)\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m env\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mimicgen/envs/robomimic/robomimic/utils/env_utils.py:174\u001b[39m, in \u001b[36mcreate_env\u001b[39m\u001b[34m(env_type, env_name, render, render_offscreen, use_image_obs, use_depth_obs, **kwargs)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;66;03m# note: pass @postprocess_visual_obs True, to make sure images are processed for network inputs\u001b[39;00m\n\u001b[32m    173\u001b[39m env_class = get_env_class(env_type=env_type)\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m env = \u001b[43menv_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43menv_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrender\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrender_offscreen\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrender_offscreen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_image_obs\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_image_obs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_depth_obs\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_depth_obs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpostprocess_visual_obs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCreated environment with name \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(env_name))\n\u001b[32m    184\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAction size is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(env.action_dimension))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mimicgen/envs/robomimic/robomimic/envs/env_robosuite.py:100\u001b[39m, in \u001b[36mEnvRobosuite.__init__\u001b[39m\u001b[34m(self, env_name, render, render_offscreen, use_image_obs, use_depth_obs, postprocess_visual_obs, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28mself\u001b[39m._env_name = env_name\n\u001b[32m     99\u001b[39m \u001b[38;5;28mself\u001b[39m._init_kwargs = deepcopy(kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m \u001b[38;5;28mself\u001b[39m.env = \u001b[43mrobosuite\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_env_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_v1:\n\u001b[32m    103\u001b[39m     \u001b[38;5;66;03m# Make sure joint position observations and eef vel observations are active\u001b[39;00m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ob_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.env.observation_names:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mimicgen/envs/robosuite/robosuite/environments/base.py:40\u001b[39m, in \u001b[36mmake\u001b[39m\u001b[34m(env_name, *args, **kwargs)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m env_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m REGISTERED_ENVS:\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[32m     36\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEnvironment \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m not found. Make sure it is a registered environment among: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m     37\u001b[39m             env_name, \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(REGISTERED_ENVS)\n\u001b[32m     38\u001b[39m         )\n\u001b[32m     39\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mREGISTERED_ENVS\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mimicgen/envs/robosuite/robosuite/environments/manipulation/nut_assembly.py:698\u001b[39m, in \u001b[36mNutAssemblySquare.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    696\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs):\n\u001b[32m    697\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33msingle_object_mode\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnut_type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs, \u001b[33m\"\u001b[39m\u001b[33minvalid set of arguments\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msingle_object_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnut_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msquare\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mimicgen/envs/robosuite/robosuite/environments/manipulation/nut_assembly.py:213\u001b[39m, in \u001b[36mNutAssembly.__init__\u001b[39m\u001b[34m(self, robots, env_configuration, controller_configs, gripper_types, initialization_noise, table_full_size, table_friction, use_camera_obs, use_object_obs, reward_scale, reward_shaping, placement_initializer, single_object_mode, nut_type, has_renderer, has_offscreen_renderer, render_camera, render_collision_mesh, render_visual_mesh, render_gpu_device_id, control_freq, horizon, ignore_done, hard_reset, camera_names, camera_heights, camera_widths, camera_depths, camera_segmentations, renderer, renderer_config)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;66;03m# object placement initializer\u001b[39;00m\n\u001b[32m    211\u001b[39m \u001b[38;5;28mself\u001b[39m.placement_initializer = placement_initializer\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrobots\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrobots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43menv_configuration\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontroller_configs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontroller_configs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmount_types\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdefault\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgripper_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgripper_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitialization_noise\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitialization_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_camera_obs\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_camera_obs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_renderer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_renderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_offscreen_renderer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_offscreen_renderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrender_camera\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrender_camera\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrender_collision_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrender_collision_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrender_visual_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrender_visual_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrender_gpu_device_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrender_gpu_device_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontrol_freq\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontrol_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhorizon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_done\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_done\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhard_reset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhard_reset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcamera_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcamera_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcamera_heights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcamera_heights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcamera_widths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcamera_widths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcamera_depths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcamera_depths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcamera_segmentations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcamera_segmentations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrenderer_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrenderer_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mimicgen/envs/robosuite/robosuite/environments/manipulation/manipulation_env.py:162\u001b[39m, in \u001b[36mManipulationEnv.__init__\u001b[39m\u001b[34m(self, robots, env_configuration, controller_configs, mount_types, gripper_types, initialization_noise, use_camera_obs, has_renderer, has_offscreen_renderer, render_camera, render_collision_mesh, render_visual_mesh, render_gpu_device_id, control_freq, horizon, ignore_done, hard_reset, camera_names, camera_heights, camera_widths, camera_depths, camera_segmentations, renderer, renderer_config)\u001b[39m\n\u001b[32m    154\u001b[39m robot_configs = [\n\u001b[32m    155\u001b[39m     {\n\u001b[32m    156\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mgripper_type\u001b[39m\u001b[33m\"\u001b[39m: gripper_types[idx],\n\u001b[32m    157\u001b[39m     }\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_robots)\n\u001b[32m    159\u001b[39m ]\n\u001b[32m    161\u001b[39m \u001b[38;5;66;03m# Run superclass init\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrobots\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrobots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[43menv_configuration\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontroller_configs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontroller_configs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmount_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmount_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitialization_noise\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitialization_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_camera_obs\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_camera_obs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_renderer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_renderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_offscreen_renderer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_offscreen_renderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrender_camera\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrender_camera\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrender_collision_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrender_collision_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrender_visual_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrender_visual_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrender_gpu_device_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrender_gpu_device_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontrol_freq\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontrol_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhorizon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_done\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_done\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhard_reset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhard_reset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcamera_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcamera_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcamera_heights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcamera_heights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcamera_widths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcamera_widths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcamera_depths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcamera_depths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcamera_segmentations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcamera_segmentations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrobot_configs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrobot_configs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrenderer_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrenderer_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mimicgen/envs/robosuite/robosuite/environments/robot_env.py:214\u001b[39m, in \u001b[36mRobotEnv.__init__\u001b[39m\u001b[34m(self, robots, env_configuration, mount_types, controller_configs, initialization_noise, use_camera_obs, has_renderer, has_offscreen_renderer, render_camera, render_collision_mesh, render_visual_mesh, render_gpu_device_id, control_freq, horizon, ignore_done, hard_reset, camera_names, camera_heights, camera_widths, camera_depths, camera_segmentations, robot_configs, renderer, renderer_config)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28mself\u001b[39m.robot_configs = [\n\u001b[32m    201\u001b[39m     \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    202\u001b[39m         **{\n\u001b[32m   (...)\u001b[39m\u001b[32m    210\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m idx, robot_config \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(robot_configs)\n\u001b[32m    211\u001b[39m ]\n\u001b[32m    213\u001b[39m \u001b[38;5;66;03m# Run superclass init\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_renderer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_renderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_offscreen_renderer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhas_offscreen_renderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrender_camera\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrender_camera\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrender_collision_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrender_collision_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrender_visual_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrender_visual_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrender_gpu_device_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrender_gpu_device_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontrol_freq\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontrol_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhorizon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_done\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_done\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhard_reset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhard_reset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrenderer_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrenderer_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mimicgen/envs/robosuite/robosuite/environments/base.py:143\u001b[39m, in \u001b[36mMujocoEnv.__init__\u001b[39m\u001b[34m(self, has_renderer, has_offscreen_renderer, render_camera, render_collision_mesh, render_visual_mesh, render_gpu_device_id, control_freq, horizon, ignore_done, hard_reset, renderer, renderer_config)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28mself\u001b[39m.initialize_renderer()\n\u001b[32m    142\u001b[39m \u001b[38;5;66;03m# Run all further internal (re-)initialization required\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reset_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[38;5;66;03m# Load observables\u001b[39;00m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.viewer, \u001b[33m\"\u001b[39m\u001b[33m_setup_observables\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mimicgen/envs/robosuite/robosuite/environments/manipulation/nut_assembly.py:592\u001b[39m, in \u001b[36mNutAssembly._reset_internal\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    588\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_reset_internal\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    589\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    590\u001b[39m \u001b[33;03m    Resets simulation internal configurations.\u001b[39;00m\n\u001b[32m    591\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_reset_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    594\u001b[39m     \u001b[38;5;66;03m# Reset all object positions using initializer sampler if we're not directly loading from an xml\u001b[39;00m\n\u001b[32m    595\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.deterministic_reset:\n\u001b[32m    596\u001b[39m \n\u001b[32m    597\u001b[39m         \u001b[38;5;66;03m# Sample from the placement initializer for all objects\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mimicgen/envs/robosuite/robosuite/environments/robot_env.py:510\u001b[39m, in \u001b[36mRobotEnv._reset_internal\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    506\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    507\u001b[39m \u001b[33;03mResets simulation internal configurations.\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    509\u001b[39m \u001b[38;5;66;03m# Run superclass reset functionality\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m510\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_reset_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[38;5;66;03m# Reset controllers\u001b[39;00m\n\u001b[32m    513\u001b[39m reset_controllers()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mimicgen/envs/robosuite/robosuite/environments/base.py:299\u001b[39m, in \u001b[36mMujocoEnv._reset_internal\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.has_offscreen_renderer:\n\u001b[32m    298\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sim._render_context_offscreen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m         render_context = \u001b[43mMjRenderContextOffscreen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrender_gpu_device_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    300\u001b[39m     \u001b[38;5;28mself\u001b[39m.sim._render_context_offscreen.vopt.geomgroup[\u001b[32m0\u001b[39m] = \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.render_collision_mesh \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    301\u001b[39m     \u001b[38;5;28mself\u001b[39m.sim._render_context_offscreen.vopt.geomgroup[\u001b[32m1\u001b[39m] = \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.render_visual_mesh \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mimicgen/envs/robosuite/robosuite/utils/binding_utils.py:210\u001b[39m, in \u001b[36mMjRenderContextOffscreen.__init__\u001b[39m\u001b[34m(self, sim, device_id, max_width, max_height)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, sim, device_id, max_width=\u001b[32m640\u001b[39m, max_height=\u001b[32m480\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffscreen\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_width\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_height\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_height\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mimicgen/envs/robosuite/robosuite/utils/binding_utils.py:78\u001b[39m, in \u001b[36mMjRenderContext.__init__\u001b[39m\u001b[34m(self, sim, offscreen, device_id, max_width, max_height)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28mself\u001b[39m.device_id = device_id\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# setup GL context with defaults for now\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m \u001b[38;5;28mself\u001b[39m.gl_ctx = \u001b[43mGLContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_width\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_height\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28mself\u001b[39m.gl_ctx.make_current()\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# Ensure the model data has been updated so that there\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# is something to render\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mimicgen/envs/robosuite/robosuite/renderers/context/egl_context.py:123\u001b[39m, in \u001b[36mEGLGLContext.__init__\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    121\u001b[39m     EGL_DISPLAY = create_initialized_egl_device_display(device_id=device_id)\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m EGL_DISPLAY == EGL.EGL_NO_DISPLAY:\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    124\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mCannot initialize a EGL device display. This likely means that your EGL \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    125\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mdriver does not support the PLATFORM_DEVICE extension, which is \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    126\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mrequired for creating a headless rendering context.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    127\u001b[39m         )\n\u001b[32m    128\u001b[39m     atexit.register(EGL.eglTerminate, EGL_DISPLAY)\n\u001b[32m    129\u001b[39m EGL.eglChooseConfig(EGL_DISPLAY, EGL_ATTRIBUTES, ctypes.byref(config), config_size, num_configs)\n",
      "\u001b[31mImportError\u001b[39m: Cannot initialize a EGL device display. This likely means that your EGL driver does not support the PLATFORM_DEVICE extension, which is required for creating a headless rendering context."
     ]
    }
   ],
   "source": [
    "log_dir, ckpt_dir, video_dir = TrainUtils.get_exp_dir(config)\n",
    "\n",
    "if config.experiment.logging.terminal_output_to_txt:\n",
    "    # log stdout and stderr to a text file\n",
    "    logger = PrintLogger(os.path.join(log_dir, 'log.txt'))\n",
    "    sys.stdout = logger\n",
    "    sys.stderr = logger\n",
    "\n",
    " \n",
    "envs = OrderedDict()\n",
    "if config.experiment.rollout.enabled:\n",
    "    # create environments for validation runs\n",
    "    env_names = [env_meta[\"env_name\"]]\n",
    "\n",
    "    if config.experiment.additional_envs is not None:\n",
    "        for name in config.experiment.additional_envs:\n",
    "            env_names.append(name)\n",
    "\n",
    "    for env_name in env_names:\n",
    "        env = EnvUtils.create_env_from_metadata(\n",
    "            env_meta=env_meta,\n",
    "            env_name=env_name, \n",
    "            render=False, \n",
    "            render_offscreen=config.experiment.render_video,\n",
    "            use_image_obs=shape_meta[\"use_images\"], \n",
    "        )\n",
    "        env = EnvUtils.wrap_env_from_config(env, config=config) # apply environment warpper, if applicable\n",
    "        envs[env.name] = env\n",
    "        print(envs[env.name])\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# setup for a new training run\n",
    "data_logger = DataLogger(\n",
    "    log_dir,\n",
    "    config,\n",
    "    log_tb=config.experiment.logging.log_tb,\n",
    "    log_wandb=config.experiment.logging.log_wandb,\n",
    ")\n",
    "model = algo_factory(\n",
    "    algo_name=config.algo_name,\n",
    "    config=config,\n",
    "    obs_key_shapes=shape_meta[\"all_shapes\"],\n",
    "    ac_dim=shape_meta[\"ac_dim\"],\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# save the config as a json file\n",
    "with open(os.path.join(log_dir, '..', 'config.json'), 'w') as outfile:\n",
    "    json.dump(config, outfile, indent=4)\n",
    "\n",
    " \n",
    "# load training data\n",
    "# trainset, validset = TrainUtils.load_data_for_training(\n",
    "#     config, obs_keys=shape_meta[\"all_obs_keys\"])\n",
    "\n",
    "validset=None\n",
    "\n",
    "\n",
    "train_sampler = trainset.get_dataset_sampler() \n",
    "print(\"\\n============= Training Dataset =============\")\n",
    "print(trainset)\n",
    "print(\"\") \n",
    "\n",
    "# maybe retreve statistics for normalizing observations\n",
    "obs_normalization_stats = None\n",
    "if config.train.hdf5_normalize_obs:\n",
    "    obs_normalization_stats = trainset.get_obs_normalization_stats()\n",
    "\n",
    "# initialize data loaders\n",
    "train_loader = DataLoader(\n",
    "    dataset=trainset,\n",
    "    sampler=train_sampler,\n",
    "    batch_size=config.train.batch_size,\n",
    "    shuffle=(train_sampler is None),\n",
    "    num_workers=config.train.num_data_workers,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "if config.experiment.validate:\n",
    "    # cap num workers for validation dataset at 1\n",
    "    num_workers = min(config.train.num_data_workers, 1)\n",
    "    valid_sampler = validset.get_dataset_sampler()\n",
    "    valid_loader = DataLoader(\n",
    "        dataset=validset,\n",
    "        sampler=valid_sampler,\n",
    "        batch_size=config.train.batch_size,\n",
    "        shuffle=(valid_sampler is None),\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True\n",
    "    )\n",
    "else:\n",
    "    valid_loader = None\n",
    "\n",
    "# print all warnings before training begins\n",
    "print(\"*\" * 50)\n",
    "print(\"Warnings generated by robomimic have been duplicated here (from above) for convenience. Please check them carefully.\")\n",
    "flush_warnings()\n",
    "print(\"*\" * 50)\n",
    "print(\"\")\n",
    "\n",
    "# main training loop\n",
    "best_valid_loss = None\n",
    "best_return = {k: -np.inf for k in envs} if config.experiment.rollout.enabled else None\n",
    "best_success_rate = {k: -1. for k in envs} if config.experiment.rollout.enabled else None\n",
    "last_ckpt_time = time.time()\n",
    "\n",
    "# number of learning steps per epoch (defaults to a full dataset pass)\n",
    "train_num_steps = config.experiment.epoch_every_n_steps\n",
    "valid_num_steps = config.experiment.validation_epoch_every_n_steps\n",
    "\n",
    "for epoch in range(1, config.train.num_epochs + 1): # epoch numbers start at 1\n",
    "    step_log = TrainUtils.run_epoch(\n",
    "        model=model,\n",
    "        data_loader=train_loader,\n",
    "        epoch=epoch,\n",
    "        num_steps=train_num_steps,\n",
    "        obs_normalization_stats=obs_normalization_stats,\n",
    "    )\n",
    "    model.on_epoch_end(epoch)\n",
    "\n",
    "    # setup checkpoint path\n",
    "    epoch_ckpt_name = \"model_epoch_{}\".format(epoch)\n",
    "\n",
    "    # check for recurring checkpoint saving conditions\n",
    "    should_save_ckpt = False\n",
    "    if config.experiment.save.enabled:\n",
    "        time_check = (config.experiment.save.every_n_seconds is not None) and \\\n",
    "            (time.time() - last_ckpt_time > config.experiment.save.every_n_seconds)\n",
    "        epoch_check = (config.experiment.save.every_n_epochs is not None) and \\\n",
    "            (epoch > 0) and (epoch % config.experiment.save.every_n_epochs == 0)\n",
    "        epoch_list_check = (epoch in config.experiment.save.epochs)\n",
    "        should_save_ckpt = (time_check or epoch_check or epoch_list_check)\n",
    "    ckpt_reason = None\n",
    "    if should_save_ckpt:\n",
    "        last_ckpt_time = time.time()\n",
    "        ckpt_reason = \"time\"\n",
    "\n",
    "    print(\"Train Epoch {}\".format(epoch))\n",
    "    print(json.dumps(step_log, sort_keys=True, indent=4))\n",
    "    for k, v in step_log.items():\n",
    "        if k.startswith(\"Time_\"):\n",
    "            data_logger.record(\"Timing_Stats/Train_{}\".format(k[5:]), v, epoch)\n",
    "        else:\n",
    "            data_logger.record(\"Train/{}\".format(k), v, epoch)\n",
    "\n",
    "    # Evaluate the model on validation set\n",
    "    if config.experiment.validate:\n",
    "        with torch.no_grad():\n",
    "            step_log = TrainUtils.run_epoch(model=model, data_loader=valid_loader, epoch=epoch, validate=True, num_steps=valid_num_steps)\n",
    "        for k, v in step_log.items():\n",
    "            if k.startswith(\"Time_\"):\n",
    "                data_logger.record(\"Timing_Stats/Valid_{}\".format(k[5:]), v, epoch)\n",
    "            else:\n",
    "                data_logger.record(\"Valid/{}\".format(k), v, epoch)\n",
    "\n",
    "        print(\"Validation Epoch {}\".format(epoch))\n",
    "        print(json.dumps(step_log, sort_keys=True, indent=4))\n",
    "\n",
    "        # save checkpoint if achieve new best validation loss\n",
    "        valid_check = \"Loss\" in step_log\n",
    "        if valid_check and (best_valid_loss is None or (step_log[\"Loss\"] <= best_valid_loss)):\n",
    "            best_valid_loss = step_log[\"Loss\"]\n",
    "            if config.experiment.save.enabled and config.experiment.save.on_best_validation:\n",
    "                epoch_ckpt_name += \"_best_validation_{}\".format(best_valid_loss)\n",
    "                should_save_ckpt = True\n",
    "                ckpt_reason = \"valid\" if ckpt_reason is None else ckpt_reason\n",
    "\n",
    "    # Evaluate the model by by running rollouts\n",
    "\n",
    "    # do rollouts at fixed rate or if it's time to save a new ckpt\n",
    "    video_paths = None\n",
    "    rollout_check = (epoch % config.experiment.rollout.rate == 0) or (should_save_ckpt and ckpt_reason == \"time\")\n",
    "    if config.experiment.rollout.enabled and (epoch > config.experiment.rollout.warmstart) and rollout_check:\n",
    "\n",
    "        # wrap model as a RolloutPolicy to prepare for rollouts\n",
    "        rollout_model = RolloutPolicy(model, obs_normalization_stats=obs_normalization_stats)\n",
    "\n",
    "        num_episodes = config.experiment.rollout.n\n",
    "        all_rollout_logs, video_paths = TrainUtils.rollout_with_stats(\n",
    "            policy=rollout_model,\n",
    "            envs=envs,\n",
    "            horizon=config.experiment.rollout.horizon,\n",
    "            use_goals=config.use_goals,\n",
    "            num_episodes=num_episodes,\n",
    "            render=False,\n",
    "            video_dir=video_dir if config.experiment.render_video else None,\n",
    "            epoch=epoch,\n",
    "            video_skip=config.experiment.get(\"video_skip\", 5),\n",
    "            terminate_on_success=config.experiment.rollout.terminate_on_success,\n",
    "        )\n",
    "\n",
    "        # summarize results from rollouts to tensorboard and terminal\n",
    "        for env_name in all_rollout_logs:\n",
    "            rollout_logs = all_rollout_logs[env_name]\n",
    "            for k, v in rollout_logs.items():\n",
    "                if k.startswith(\"Time_\"):\n",
    "                    data_logger.record(\"Timing_Stats/Rollout_{}_{}\".format(env_name, k[5:]), v, epoch)\n",
    "                else:\n",
    "                    data_logger.record(\"Rollout/{}/{}\".format(k, env_name), v, epoch, log_stats=True)\n",
    "\n",
    "            print(\"\\nEpoch {} Rollouts took {}s (avg) with results:\".format(epoch, rollout_logs[\"time\"]))\n",
    "            print('Env: {}'.format(env_name))\n",
    "            print(json.dumps(rollout_logs, sort_keys=True, indent=4))\n",
    "\n",
    "        # checkpoint and video saving logic\n",
    "        updated_stats = TrainUtils.should_save_from_rollout_logs(\n",
    "            all_rollout_logs=all_rollout_logs,\n",
    "            best_return=best_return,\n",
    "            best_success_rate=best_success_rate,\n",
    "            epoch_ckpt_name=epoch_ckpt_name,\n",
    "            save_on_best_rollout_return=config.experiment.save.on_best_rollout_return,\n",
    "            save_on_best_rollout_success_rate=config.experiment.save.on_best_rollout_success_rate,\n",
    "        )\n",
    "        best_return = updated_stats[\"best_return\"]\n",
    "        best_success_rate = updated_stats[\"best_success_rate\"]\n",
    "        epoch_ckpt_name = updated_stats[\"epoch_ckpt_name\"]\n",
    "        should_save_ckpt = (config.experiment.save.enabled and updated_stats[\"should_save_ckpt\"]) or should_save_ckpt\n",
    "        if updated_stats[\"ckpt_reason\"] is not None:\n",
    "            ckpt_reason = updated_stats[\"ckpt_reason\"]\n",
    "\n",
    "    # Only keep saved videos if the ckpt should be saved (but not because of validation score)\n",
    "    should_save_video = (should_save_ckpt and (ckpt_reason != \"valid\")) or config.experiment.keep_all_videos\n",
    "    if video_paths is not None and not should_save_video:\n",
    "        for env_name in video_paths:\n",
    "            os.remove(video_paths[env_name])\n",
    "\n",
    "    # Save model checkpoints based on conditions (success rate, validation loss, etc)\n",
    "    if should_save_ckpt:\n",
    "        TrainUtils.save_model(\n",
    "            model=model,\n",
    "            config=config,\n",
    "            env_meta=env_meta,\n",
    "            shape_meta=shape_meta,\n",
    "            ckpt_path=os.path.join(ckpt_dir, epoch_ckpt_name + \".pth\"),\n",
    "            obs_normalization_stats=obs_normalization_stats,\n",
    "        )\n",
    "\n",
    "    # Finally, log memory usage in MB\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_usage = int(process.memory_info().rss / 1000000)\n",
    "    data_logger.record(\"System/RAM Usage (MB)\", mem_usage, epoch)\n",
    "    print(\"\\nEpoch {} Memory Usage: {} MB\\n\".format(epoch, mem_usage))\n",
    "\n",
    "# terminate logging\n",
    "data_logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
